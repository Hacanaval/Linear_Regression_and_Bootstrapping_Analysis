{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94f95f0-ee19-48b6-b5f0-5c4bcb02a3ea",
   "metadata": {},
   "source": [
    "### Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fac06406-a706-49ce-8717-0a7e468537de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor  # Árboles de decisión (clasificación y regresión)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor  # Random Forest (clasificación y regresión)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression  # Regresión logística y lineal\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, r2_score, f1_score, precision_score, recall_score\n",
    "set_config(print_changed_only=False)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error  # Añadimos mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d51c1-dc3a-4240-99f5-804507b9d446",
   "metadata": {},
   "source": [
    "### Cargamos bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5113be63-a452-47cc-90cf-2063320f7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_0 = pd.read_csv('/Users/hacanaval/MEGA/MEGAsync/Academico/Tripleten - Data Science 2025/Sprint 11/carpeta sin título/Data/geo_data_0.csv')\n",
    "data_1 = pd.read_csv('/Users/hacanaval/MEGA/MEGAsync/Academico/Tripleten - Data Science 2025/Sprint 11/carpeta sin título/Data/geo_data_1.csv')\n",
    "data_2 = pd.read_csv('/Users/hacanaval/MEGA/MEGAsync/Academico/Tripleten - Data Science 2025/Sprint 11/carpeta sin título/Data/geo_data_2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f3ec6-87d7-4d5b-b046-9ee03f4d3fb0",
   "metadata": {},
   "source": [
    "### Realizamos estadistica descriptiva en las bases de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab64d1-04de-4f77-8e67-a88d3f1692ca",
   "metadata": {},
   "source": [
    "#### Revisamos valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a517cac2-bf5f-49c1-b642-b90c39275805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_0 \n",
      " id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "\n",
      " data_1 \n",
      " id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n",
      "\n",
      " data_2 \n",
      " id         0\n",
      "f0         0\n",
      "f1         0\n",
      "f2         0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print ('data_0 \\n',data_0.isna().sum())\n",
    "print ('\\n data_1 \\n',data_1.isna().sum())\n",
    "print ('\\n data_2 \\n',data_2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03e130-a173-4116-a0ff-57f272aed409",
   "metadata": {},
   "source": [
    "#### Revisamos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae151718-2571-48c4-86de-6a22ccf03453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_0 \n",
      " 0\n",
      "\n",
      " data_1 \n",
      " 0\n",
      "\n",
      " data_2 \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print ('data_0 \\n',data_0.duplicated().sum())\n",
    "print ('\\n data_1 \\n',data_1.duplicated().sum())\n",
    "print ('\\n data_2 \\n',data_2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201dde5-5b59-4d76-8739-6d1aa97b5df3",
   "metadata": {},
   "source": [
    "#### Revisamos info y describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f1d17f-fbf6-4d6f-81d1-fcffced1945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "data_0 \n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      " data_1 \n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "\n",
      " data_2 \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print ('data_0 \\n',data_0.info())\n",
    "print ('\\n data_1 \\n',data_1.info())\n",
    "print ('\\n data_2 \\n',data_2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "753268c6-5c97-4672-8741-ac8d4519f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_0 \n",
      "                   f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.500419       0.250143       2.502647      92.500000\n",
      "std         0.871832       0.504433       3.248248      44.288691\n",
      "min        -1.408605      -0.848218     -12.088328       0.000000\n",
      "25%        -0.072580      -0.200881       0.287748      56.497507\n",
      "50%         0.502360       0.250252       2.515969      91.849972\n",
      "75%         1.073581       0.700646       4.715088     128.564089\n",
      "max         2.362331       1.343769      16.003790     185.364347\n",
      "\n",
      " data_1 \n",
      "                   f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        1.141296      -4.796579       2.494541      68.825000\n",
      "std         8.965932       5.119872       1.703572      45.944423\n",
      "min       -31.609576     -26.358598      -0.018144       0.000000\n",
      "25%        -6.298551      -8.267985       1.000021      26.953261\n",
      "50%         1.153055      -4.813172       2.011479      57.085625\n",
      "75%         8.621015      -1.332816       3.999904     107.813044\n",
      "max        29.421755      18.734063       5.019721     137.945408\n",
      "\n",
      " data_2 \n",
      "                   f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.002023      -0.002081       2.495128      95.000000\n",
      "std         1.732045       1.730417       3.473445      44.749921\n",
      "min        -8.760004      -7.084020     -11.970335       0.000000\n",
      "25%        -1.162288      -1.174820       0.130359      59.450441\n",
      "50%         0.009424      -0.009482       2.484236      94.925613\n",
      "75%         1.158535       1.163678       4.858794     130.595027\n",
      "max         7.238262       7.844801      16.739402     190.029838\n"
     ]
    }
   ],
   "source": [
    "print ('data_0 \\n',data_0.describe())\n",
    "print ('\\n data_1 \\n',data_1.describe())\n",
    "print ('\\n data_2 \\n',data_2.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b27938-112c-44b3-8f52-c09cfea0d61d",
   "metadata": {},
   "source": [
    "### Resumen de los datasets\n",
    "\n",
    "#### **data_0**\n",
    "- **f0**: Valores típicos cerca de 0.5 (varía entre -1.4 y 2.4).  \n",
    "- **f1**: Centrado en 0.25, con valores entre -0.8 y 1.3.  \n",
    "- **f2**: Promedio ≈2.5, pero con valores desde -12 hasta 16.  \n",
    "- **product**: La mayoría entre 56 y 128 (promedio 92.5).  \n",
    "\n",
    "**Nota**: Datos equilibrados, sin valores extremos preocupantes.\n",
    "\n",
    "---\n",
    "\n",
    "#### **data_1**\n",
    "- **f0**: Valores muy dispersos (de -31 a 29), promedio ≈1.1.  \n",
    "- **f1**: Fuertemente negativo (promedio ≈-4.8), con valores entre -26 y 18.  \n",
    "- **f2**: Casi todos entre 1 y 4 (promedio ≈2.5).  \n",
    "- **product**: Más bajo que otros (promedio 68.8), mitad de los datos entre 27 y 108.  \n",
    "\n",
    "**Nota**: Tiene valores extremos y comportamientos más volátiles.\n",
    "\n",
    "---\n",
    "\n",
    "#### **data_2**\n",
    "- **f0** y **f1**: Simétricos alrededor de 0 (promedio ≈0).  \n",
    "- **f2**: Similar a `data_0` (promedio ≈2.5, valores desde -12 hasta 16.7).  \n",
    "- **product**: El más alto (promedio 95), mitad de los datos entre 59 y 130.  \n",
    "\n",
    "**Nota**: Datos balanceados, con `f0` y `f1` actuando como opuestos.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Conclusión rápida**\n",
    "- **data_0**: Datos estables y predecibles.  \n",
    "- **data_1**: Ideal para estudiar casos extremos o anomalías.  \n",
    "- **data_2**: Perfecto para buscar simetría y valores altos en `product`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6d270-9710-418a-bbcc-f187a798dc80",
   "metadata": {},
   "source": [
    "### Entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8fd897ed-1a67-4a15-89b8-2daabc3abf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los datos en un conjunto de entrenamiento y otro de validación\n",
    "\n",
    "#Creamos función \n",
    "\n",
    "def split_data(data, target_column, test_size=0.25, random_state=12345):\n",
    "    x = data.drop(['id', target_column], axis=1)\n",
    "    y = data[target_column]\n",
    "    return train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Aplicamos la función a cada dataset\n",
    "\n",
    "x_0_train, x_0_valid, y_0_train, y_0_valid = split_data(data_0, 'product')\n",
    "x_1_train, x_1_valid, y_1_train, y_1_valid = split_data(data_1, 'product')\n",
    "x_2_train, x_2_valid, y_2_train, y_2_valid = split_data(data_2, 'product')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbdc7e-db07-4852-8a9d-2ee04868be32",
   "metadata": {},
   "source": [
    "### data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f588f4a3-11ca-4fa7-9653-5d2e5f98c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE por CV: [37.69824774 37.7856609  37.65173283 37.85075184 37.67551612]\n",
      "RMSE promedio: 37.73238188617926\n",
      "R² por CV: [0.26543147 0.27779784 0.28135147 0.27476308 0.27108881]\n",
      "R² promedio: 0.27408653371000735\n",
      "MAE por CV: [31.01002792 31.15688621 31.10393433 31.1474995  30.9894004 ]\n",
      "MAE promedio: 31.081549673170162\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo y validamos con validación cruzada usando diferentes metricas\n",
    "# Usamos validación cruzada en el dataset de entrenamiento para asegurarnos que el modelo no depende de una división especifica\n",
    "\n",
    "model_0 = LinearRegression()\n",
    "MSE_0 = cross_val_score(model_0,x_0_train,y_0_train,cv=5,scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convertimos el MSE a RMSE\n",
    "rmse_scores = np.sqrt(-MSE_0)  # Tomamos la raíz cuadrada del valor absoluto del MSE negativo\n",
    "rmse_mean = rmse_scores.mean()\n",
    "rmse_std = rmse_scores.std()\n",
    "\n",
    "#R²\n",
    "R2_0 = cross_val_score(model_0,x_0_train,y_0_train,cv=5,scoring='r2')\n",
    "\n",
    "#MAE\n",
    "MAE_0 = cross_val_score(model_0,x_0_train,y_0_train,cv=5,scoring='neg_mean_absolute_error')\n",
    "MAE_0 = -MAE_0\n",
    "\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"RMSE por CV:\", rmse_scores)\n",
    "print(\"RMSE promedio:\", rmse_mean)\n",
    "print(\"R² por CV:\", R2_0)\n",
    "print(\"R² promedio:\", R2_0.mean())\n",
    "print(\"MAE por CV:\", MAE_0)\n",
    "print(\"MAE promedio:\", MAE_0.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cba3a774-2057-4194-bb25-d7a8165fab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En conjunto de validación\n",
      "Volumen medio predicho: 92.59256778438038\n",
      "RMSE: 37.5794217150813\n",
      "R²: 0.27994321524487786\n",
      "MAE: 30.919600777151313\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en validación\n",
    "prediction_valid_0 = model_0.fit(x_0_train, y_0_train).predict(x_0_valid)\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_0_valid, prediction_valid_0))\n",
    "r2_valid = r2_score(y_0_valid, prediction_valid_0)\n",
    "mae_valid = mean_absolute_error(y_0_valid, prediction_valid_0)\n",
    "mean_predicted_0 = prediction_valid_0.mean()\n",
    "\n",
    "print(\"En conjunto de validación\")\n",
    "print(f\"Volumen medio predicho: {mean_predicted_0}\")\n",
    "print(f\"RMSE: {rmse_valid}\")\n",
    "print(f\"R²: {r2_valid}\")\n",
    "print(f\"MAE: {mae_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84568b02-f0f9-4a9b-9efb-ee689270975d",
   "metadata": {},
   "source": [
    "#### Conclusiones metricas data_0\n",
    "\n",
    "Tanto en la validación cruzada con el dataset de entrenamiento como en las métricas de las predicciones en validación, los valores están muy cercanos, lo que indica que el modelo generaliza bien y no tiene un sesgo significativo. Es decir, no tiende a subestimar ni sobrestimar, y el rendimiento es consistente entre entrenamiento y validación\n",
    "\n",
    "Con respecto al **RMSE**, relativo a la media, el error está aproximadamente en un 40% (37.6 / 92.5). Esto representa un error significativo, y las predicciones podrían desviarse del valor real, lo que podría afectar la selección de los 200 mejores pozos\n",
    "\n",
    "El **R²** indica que el modelo explica el 28% de la variación de product. Es un R² relativamente bajo, sugiriendo que las variables independientes no capturan bien la relación con la variable a predecir. Posiblemente no hay una relación lineal\n",
    "\n",
    "Analizando el **MAE**, relativo a la media, el error está aproximadamente en un 33%, siendo menor que el RMSE, lo que indica que los errores grandes no son tan dominantes. Sin embargo, el error sigue siendo considerablemente alto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905c009-3974-4a37-80e3-6c5056dacb98",
   "metadata": {},
   "source": [
    "#### Creamos una función para reutilizar lo anterior hecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ef4e4e0-437e-44e8-9736-d6c224b26b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_region(data, target_column='product', test_size=0.25, random_state=12345):\n",
    "    # Dividimos los datos en entrenamiento y validación\n",
    "    x = data.drop(['id', target_column], axis=1)\n",
    "    y = data[target_column]\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Creamos y entrenamos el modelo\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Validación cruzada en el conjunto de entrenamiento\n",
    "    mse_cv = cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_cv = np.sqrt(-mse_cv)  # Convertimos MSE a RMSE\n",
    "    r2_cv = cross_val_score(model, x_train, y_train, cv=5, scoring='r2')\n",
    "    mae_cv = -cross_val_score(model, x_train, y_train, cv=5, scoring='neg_mean_absolute_error')  # Convertimos a positivo\n",
    "    \n",
    "    # Predicciones en el conjunto de validación\n",
    "    model.fit(x_train, y_train)  # Entrenamos con todos los datos de entrenamiento\n",
    "    predictions_valid = model.predict(x_valid)\n",
    "    mean_predicted = predictions_valid.mean()\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_valid, predictions_valid))\n",
    "    r2_valid = r2_score(y_valid, predictions_valid)\n",
    "    mae_valid = mean_absolute_error(y_valid, predictions_valid)\n",
    "    \n",
    "    # Mostramos los resultados\n",
    "    print(f\"Región {data.name if hasattr(data, 'name') else 'sin nombre'}\")\n",
    "    print(\"Validación cruzada (entrenamiento):\")\n",
    "    print(f\"RMSE promedio: {rmse_cv.mean():.2f}\")\n",
    "    print(f\"R² promedio: {r2_cv.mean():.2f}\")\n",
    "    print(f\"MAE promedio: {mae_cv.mean():.2f}\")\n",
    "    print(\"\\nConjunto de validación:\")\n",
    "    print(f\"Volumen medio predicho: {mean_predicted:.2f}\")\n",
    "    print(f\"RMSE: {rmse_valid:.2f}\")\n",
    "    print(f\"R²: {r2_valid:.2f}\")\n",
    "    print(f\"MAE: {mae_valid:.2f}\")\n",
    "    \n",
    "    # Devolvemos las predicciones y valores reales para usarlos después (cálculo de ganancias)\n",
    "    return predictions_valid, y_valid\n",
    "\n",
    "# Asignamos nombres a los datasets para identificarlos\n",
    "data_0.name = \"Data_0\"\n",
    "data_1.name = \"Data_1\"\n",
    "data_2.name = \"Data_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3d552cec-6928-4f62-b4b7-c40b1fc3e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región Data_0\n",
      "Validación cruzada (entrenamiento):\n",
      "RMSE promedio: 37.73\n",
      "R² promedio: 0.27\n",
      "MAE promedio: 31.08\n",
      "\n",
      "Conjunto de validación:\n",
      "Volumen medio predicho: 92.59\n",
      "RMSE: 37.58\n",
      "R²: 0.28\n",
      "MAE: 30.92\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función a data_0 para saber si quedó bien la función\n",
    "\n",
    "predictions_0, y_valid_0 = evaluate_region(data_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d8ca3-be24-4dcf-baf4-22f15d122cbc",
   "metadata": {},
   "source": [
    "### Utilizamos la funciones para evaluar los datasets data_1 y data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29cef3e6-db17-4a50-8d8b-d2c505a33ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región Data_1\n",
      "Validación cruzada (entrenamiento):\n",
      "RMSE promedio: 0.89\n",
      "R² promedio: 1.00\n",
      "MAE promedio: 0.72\n",
      "\n",
      "Conjunto de validación:\n",
      "Volumen medio predicho: 68.73\n",
      "RMSE: 0.89\n",
      "R²: 1.00\n",
      "MAE: 0.72\n"
     ]
    }
   ],
   "source": [
    "predictions_1, y_valid_1 = evaluate_region(data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e160d5ac-1db1-4464-a7ad-a617accb2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región Data_2\n",
      "Validación cruzada (entrenamiento):\n",
      "RMSE promedio: 40.07\n",
      "R² promedio: 0.20\n",
      "MAE promedio: 32.84\n",
      "\n",
      "Conjunto de validación:\n",
      "Volumen medio predicho: 94.97\n",
      "RMSE: 40.03\n",
      "R²: 0.21\n",
      "MAE: 32.79\n"
     ]
    }
   ],
   "source": [
    "predictions_2, y_valid_2 = evaluate_region(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a272eee-1a55-4fd4-9c5f-0b12fb686276",
   "metadata": {},
   "source": [
    "### Conclusiones metricas data_1 y data_2\n",
    "\n",
    "Al igual que con data_0, las métricas entre la validación cruzada y el conjunto de validación no cambian mucho, así que llegamos a la misma idea: el modelo generaliza bien y no se porta muy diferente con distintos pedazos de datos\n",
    "\n",
    "#### data_1\n",
    "\n",
    "En este caso, las métricas salen mucho mejores. Tenemos un **RMSE** de 0.89, lo que significa que, en promedio, las predicciones se equivocan por unos 890 barriles. Esto es bastante menos que el RMSE de data_0. El **MAE** está en 0.72, o sea, el error promedio es de unos 720 barriles (sin darle tanto peso a los errores grandes). Y el **R²** es 1, lo que quiere decir que el modelo explica el 100% de cómo se comporta la variable que queremos predecir con las variables que usamos\n",
    "\n",
    "#### data_2\n",
    "data_2 tiene comportamientos mas parecidos a data_0, con un **RMSE** de 40 miles de barrires, un 42% de la media. Un **MAE** de 32.79, 34% de la media. Y un **R²** bajo de 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900689d8-549f-46b7-b38b-1cf8f06be54f",
   "metadata": {},
   "source": [
    "### Preparación para el cálculo de ganancias\n",
    "\n",
    "#### Almacenamos los valores necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "20399f7c-d2ea-41a7-9a92-34cabd888b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo por pozo: $500000.0\n",
      "Ingreso por mil barriles: $4500\n",
      "Volumen mínimo por pozo: 111.1 mil barriles\n"
     ]
    }
   ],
   "source": [
    "# Datos del proyecto\n",
    "total_budget = 100000000  # 100 millones de dólares para 200 pozos\n",
    "n_wells = 200  # Número de pozos a desarrollar\n",
    "cost_per_well = total_budget / n_wells  # Costo por pozo: $500,000\n",
    "revenue_per_mil = 4500  # Ingreso por mil barriles: $4,500 ($4.5 por barril)\n",
    "min_volume_per_well = cost_per_well / revenue_per_mil  # Volumen mínimo por pozo para no perder (111.1 barriles)\n",
    "\n",
    "# Reservas promedio reales de cada región (de los datos completos)\n",
    "mean_product_0 = data_0['product'].mean()  # Promedio de data_0\n",
    "mean_product_1 = data_1['product'].mean()  # Promedio de data_1\n",
    "mean_product_2 = data_2['product'].mean()  # Promedio de data_2\n",
    "\n",
    "# Predicciones y valores reales de validación ya los tenemos de la función evaluate_region\n",
    "# Los tenemos en: predictions_0, y_valid_0, predictions_1, y_valid_1, predictions_2, y_valid_2\n",
    "\n",
    "# Cálculo del volumen mínimo\n",
    "print(f\"Costo por pozo: ${cost_per_well}\")\n",
    "print(f\"Ingreso por mil barriles: ${revenue_per_mil}\")\n",
    "print(f\"Volumen mínimo por pozo: {min_volume_per_well:.1f} mil barriles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103574c1-792b-45c5-9501-a3a171660d56",
   "metadata": {},
   "source": [
    "#### Comparamos con las reservas promedio de cada región (usando toda el dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9a3d48bc-2ecb-4184-804e-97b18c0ef098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reservas promedio reales por región:\n",
      "Data_0: 92.50 mil barriles\n",
      "Data_1: 68.83 mil barriles\n",
      "Data_2: 95.00 mil barriles\n",
      "\n",
      "¿Superan el mínimo de 111.1 mil barriles?\n",
      "Data_0: No\n",
      "Data_1: No\n",
      "Data_2: No\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las reservas promedio reales\n",
    "print(\"Reservas promedio reales por región:\")\n",
    "print(f\"Data_0: {mean_product_0:.2f} mil barriles\")\n",
    "print(f\"Data_1: {mean_product_1:.2f} mil barriles\")\n",
    "print(f\"Data_2: {mean_product_2:.2f} mil barriles\")\n",
    "\n",
    "# Comparación con el mínimo\n",
    "print(\"\\n¿Superan el mínimo de 111.1 mil barriles?\")\n",
    "print(f\"Data_0: {'Sí' if mean_product_0 > min_volume_per_well else 'No'}\")\n",
    "print(f\"Data_1: {'Sí' if mean_product_1 > min_volume_per_well else 'No'}\")\n",
    "print(f\"Data_2: {'Sí' if mean_product_2 > min_volume_per_well else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce89a0-65dc-4959-8637-376c08d5ef5d",
   "metadata": {},
   "source": [
    "Ninguna región tiene un promedio que alcance los 111.1 mil barriles. Esto significa que, en promedio, los pozos no son rentables si se eligen al azar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09657b84-f470-4cf5-9a91-9e734bb13138",
   "metadata": {},
   "source": [
    "### Creamos la función para elegir los mejores 200 pozos por región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "426046d8-1870-4446-921e-9a5c1a14a969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volumen promedio real de los 200 mejores pozos:\n",
      "Data_0: 148.01 mil barriles\n",
      "Data_1: 137.95 mil barriles\n",
      "Data_2: 141.23 mil barriles\n",
      "\n",
      "¿Superan el mínimo de 111.1 mil barriles?\n",
      "Data_0: Sí\n",
      "Data_1: Sí\n",
      "Data_2: Sí\n"
     ]
    }
   ],
   "source": [
    "# Función para seleccionar los 200 mejores pozos\n",
    "def select_top_wells(predictions, y_valid, n_wells=200):\n",
    "    pred_series = pd.Series(predictions, index=y_valid.index)\n",
    "    top_indices = pred_series.sort_values(ascending=False).head(n_wells).index\n",
    "    top_real = y_valid.loc[top_indices]\n",
    "    return top_real\n",
    "\n",
    "# Aseguramos que las predicciones y reales estén como series con índices\n",
    "predictions_0 = pd.Series(predictions_0, index=y_valid_0.index)\n",
    "predictions_1 = pd.Series(predictions_1, index=y_valid_1.index)\n",
    "predictions_2 = pd.Series(predictions_2, index=y_valid_2.index)\n",
    "\n",
    "# Seleccionamos los 200 mejores\n",
    "top_200_0 = select_top_wells(predictions_0, y_valid_0)\n",
    "top_200_1 = select_top_wells(predictions_1, y_valid_1)\n",
    "top_200_2 = select_top_wells(predictions_2, y_valid_2)\n",
    "\n",
    "# Mostramos el volumen promedio de los 200 mejores\n",
    "print(\"Volumen promedio real de los 200 mejores pozos:\")\n",
    "print(f\"Data_0: {top_200_0.mean():.2f} mil barriles\")\n",
    "print(f\"Data_1: {top_200_1.mean():.2f} mil barriles\")\n",
    "print(f\"Data_2: {top_200_2.mean():.2f} mil barriles\")\n",
    "\n",
    "# Comparación con el mínimo\n",
    "print(\"\\n¿Superan el mínimo de 111.1 mil barriles?\")\n",
    "print(f\"Data_0: {'Sí' if top_200_0.mean() > min_volume_per_well else 'No'}\")\n",
    "print(f\"Data_1: {'Sí' if top_200_1.mean() > min_volume_per_well else 'No'}\")\n",
    "print(f\"Data_2: {'Sí' if top_200_2.mean() > min_volume_per_well else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355c82c-d7ce-4ad9-9495-d7ac27a3e165",
   "metadata": {},
   "source": [
    "Al elegir los 200 mejores pozos, en promedio, todas las regions superan el mínimo de 111.1 mil barriles para ser rentables. Sin embargo, es importante tener en cuenta las métricas que vimos antes. Los datos de Data_0 y Data_2 no son tan confiables por esas métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2ac2c-9312-4e2d-a938-a6546397b2c1",
   "metadata": {},
   "source": [
    "### Calculamos las ganancias por región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d229e824-d73b-4fc7-9b3d-be3527160ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancias esperadas (en millones de $):\n",
      "Data_0: 33.21\n",
      "Data_1: 24.15\n",
      "Data_2: 27.10\n"
     ]
    }
   ],
   "source": [
    "# Datos del proyecto\n",
    "revenue_per_mil = 4500  # $4,500 por mil barriles\n",
    "total_cost = 100000000  # $100 millones\n",
    "n_wells = 200\n",
    "\n",
    "# Volúmenes promedio de los 200 mejores pozos\n",
    "mean_volume_0 = top_200_0.mean() \n",
    "mean_volume_1 = top_200_1.mean() \n",
    "mean_volume_2 = top_200_2.mean() \n",
    "\n",
    "# Función para calcular ganancias\n",
    "def calculate_profit(mean_volume, n_wells=200, revenue_per_mil=4500, total_cost=100000000):\n",
    "    total_volume = mean_volume * n_wells  # Volumen total en mil barriles\n",
    "    revenue = total_volume * revenue_per_mil  # Ingresos en $ (vol * 4500)\n",
    "    profit = revenue - total_cost  # Ganancia en $ (total_cost $100 millones por 200 pozos)\n",
    "    return profit\n",
    "\n",
    "# Calculamos las ganancias para cada región\n",
    "profit_0 = calculate_profit(mean_volume_0)\n",
    "profit_1 = calculate_profit(mean_volume_1)\n",
    "profit_2 = calculate_profit(mean_volume_2)\n",
    "\n",
    "# Mostramos los resultados en millones\n",
    "print(\"Ganancias esperadas (en millones de $):\")\n",
    "print(f\"Data_0: {profit_0 / 1_000_000:.2f}\")\n",
    "print(f\"Data_1: {profit_1 / 1_000_000:.2f}\")\n",
    "print(f\"Data_2: {profit_2 / 1_000_000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19e6d7-a490-4c36-a23a-a412a8d87440",
   "metadata": {},
   "source": [
    "### Análisis resultados\n",
    "\n",
    "A primera vista, Data_0 parece la mejor opción porque da la mayor ganancia bruta. \n",
    "Pero las métricas del modelo anteriormente calculadas nos dicen que:\n",
    "\n",
    "- Data_1 tiene predicciones casi perfectas (RMSE 0.89, R² 1.0), así que esos 137.95 mil barriles son confiables\n",
    "  \n",
    "- Data_0 y Data_2 tienen errores altos (RMSE ≈ 37-40, R² bajo), lo que significa que las predicciones pueden estar más lejos de la realidad, y esa ganancia podría no ser tan segura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d32897-9c47-4cbe-9267-775bb2692489",
   "metadata": {},
   "source": [
    "### Boostrapping\n",
    "\n",
    "Para estar seguros de cuál región elegir, vamos a:\n",
    "\n",
    "- Usar bootstrap para simular 1,000 escenarios, tomando 500 pozos al azar de las predicciones, eligiendo los 200 mejores de cada muestra, y calculando ganancias\n",
    "- Ver el promedio de ganancias, el intervalo de confianza (95%), y el riesgo de pérdida (probabilidad de que la ganancia sea negativa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a3a610af-17c1-462d-9829-c741a46d6e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del Bootstrapping:\n",
      "\n",
      "Data_0:\n",
      "\n",
      "Ganancia promedio: 3.84 millones $\n",
      "Intervalo de confianza 95%: [-1.55, 9.37] millones $\n",
      "Riesgo de pérdida: 8.10%\n",
      "\n",
      "Data_1:\n",
      "\n",
      "Ganancia promedio: 4.54 millones $\n",
      "Intervalo de confianza 95%: [0.52, 8.47] millones $\n",
      "Riesgo de pérdida: 1.50%\n",
      "\n",
      "Data_2:\n",
      "\n",
      "Ganancia promedio: 3.80 millones $\n",
      "Intervalo de confianza 95%: [-1.69, 9.23] millones $\n",
      "Riesgo de pérdida: 9.40%\n"
     ]
    }
   ],
   "source": [
    "state = np.random.RandomState(12345)\n",
    "\n",
    "# Lista para guardar las ganancias de cada región\n",
    "profits_0_list = []\n",
    "profits_1_list = []\n",
    "profits_2_list = []\n",
    "\n",
    "# Hacemos bootstrapping para cada región\n",
    "for i in range(1000):\n",
    "    # Data_0\n",
    "    subsample_indices_0 = predictions_0.sample(n=500, replace=True, random_state=state).index\n",
    "    subsample_preds_0 = predictions_0.loc[subsample_indices_0]\n",
    "    subsample_real_0 = y_valid_0.loc[subsample_indices_0]\n",
    "    top_real_0 = select_top_wells(subsample_preds_0, subsample_real_0)\n",
    "    profit_0 = calculate_profit(top_real_0.mean())\n",
    "    profits_0_list.append(profit_0)\n",
    "\n",
    "    # Data_1\n",
    "    subsample_indices_1 = predictions_1.sample(n=500, replace=True, random_state=state).index\n",
    "    subsample_preds_1 = predictions_1.loc[subsample_indices_1]\n",
    "    subsample_real_1 = y_valid_1.loc[subsample_indices_1]\n",
    "    top_real_1 = select_top_wells(subsample_preds_1, subsample_real_1)\n",
    "    profit_1 = calculate_profit(top_real_1.mean())\n",
    "    profits_1_list.append(profit_1)\n",
    "\n",
    "    # Data_2\n",
    "    subsample_indices_2 = predictions_2.sample(n=500, replace=True, random_state=state).index\n",
    "    subsample_preds_2 = predictions_2.loc[subsample_indices_2]\n",
    "    subsample_real_2 = y_valid_2.loc[subsample_indices_2]\n",
    "    top_real_2 = select_top_wells(subsample_preds_2, subsample_real_2)\n",
    "    profit_2 = calculate_profit(top_real_2.mean())\n",
    "    profits_2_list.append(profit_2)\n",
    "\n",
    "# Convertimos a series\n",
    "profits_0 = pd.Series(profits_0_list)\n",
    "profits_1 = pd.Series(profits_1_list)\n",
    "profits_2 = pd.Series(profits_2_list)\n",
    "\n",
    "# Análisis de resultados\n",
    "print(\"Resultados del Bootstrapping:\")\n",
    "for region, profits in [(\"Data_0\", profits_0), (\"Data_1\", profits_1), (\"Data_2\", profits_2)]:\n",
    "    mean_profit = profits.mean() / 1000000 \n",
    "    ci_lower = profits.quantile(0.025) / 1000000\n",
    "    ci_upper = profits.quantile(0.975) / 1000000\n",
    "    risk = (profits < 0).mean() * 100\n",
    "    print(f\"\\n{region}:\\n\")\n",
    "    print(f\"Ganancia promedio: {mean_profit:.2f} millones $\")\n",
    "    print(f\"Intervalo de confianza 95%: [{ci_lower:.2f}, {ci_upper:.2f}] millones $\")\n",
    "    print(f\"Riesgo de pérdida: {risk:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea357ee-5a6b-4252-8b3c-d9867206c9bb",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Para este caso solo analizaremos Data_1, debido a que es el unico que cumple con la condición de riesgo de pérdida < 2.5% y adicional es el unico con un invervalo de confianza (profit) netamente positivo (Data_0 y Data_2 el menor intervalo es negativo)\n",
    "\n",
    "Data_1 nos muestra una ganancia promedio de 4,5 mm, sin embargo, su intervalo de ganancia es amplio. Aunque, con un 95% de seguridad sabemos que va a ser positivo\n",
    "\n",
    "Antes del bootstrapping, calculamos las ganancias de los 200 mejores pozos usando todo el conjunto de validación. Para Data_1 fue de 24 mm. Con el bootstrap, las ganancias promedio son mucho más bajas 4.54 mm. Esto pasa porque:\n",
    "\n",
    "En el cálculo inicial, usamos los 25,000 pozos del conjunto de validación para elegir los 200 mejores, lo que maximiza las ganancias. En el bootstrapping, tomamos muestras de solo 500 pozos cada vez, lo que simula una exploración más realista y menos optimista. Esto nos da una visión más conservadora y nos muestra el riesgo real.\n",
    "Aunque las ganancias del bootstrap son más bajas, son más representativas de lo que pasaría en la vida real, y el riesgo de pérdida nos ayuda a tomar una decisión más segura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3291094-774f-4845-9978-0a15f14b448c",
   "metadata": {},
   "source": [
    "## Recomendación final\n",
    "\n",
    "Recomiendo elegir la región Data_1 para el desarrollo de los 200 pozos petrolíferos porque:\n",
    "\n",
    "- Es la única región que cumple con el criterio de riesgo de pérdida menor al 2.5% (1.50%).\n",
    "- Tiene la mayor ganancia promedio (4.54 millones $) entre las regiones que cumplen el criterio (en este caso, es la única).\n",
    "- Sus ganancias son más estables, con un intervalo de confianza más estrecho y sin valores negativos,\n",
    "- El modelo tiene métricas precisas.\n",
    "\n",
    "Elegir Data_1 no solo minimiza el riesgo de pérdidas, sino que también asegura un retorno positivo y estable, lo que es crucial para una empresa como OilyGiant que busca maximizar ganancias con un presupuesto fijo de $100 millones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f226271-d7d4-4622-a6f0-cedf44f83b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
